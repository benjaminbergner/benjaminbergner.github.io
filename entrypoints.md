---
layout: page
title: ML Entry Points
permalink: /entry/
---

Machine learning is a very broad field of research. One regularly deals with new topics, which are sometimes difficult to understand. On this page I collect links to resources that helped me to get started and are well explained. Topics are sorted alphabetically. If applicable, I sorted links in ascending order of difficulty.

**Batch Normalization**  
[Batch Normalization Explained](https://leimao.github.io/blog/Batch-Normalization/)

**Implicit Layers**  
[Deep Implicit Layers](http://implicit-layers-tutorial.org/introduction/)

**Spatial Transformer Networks**  
[Deep Learning Paper Implementations: Spatial Transformer Networks - Part I](https://kevinzakka.github.io/2017/01/10/stn-part1/)  
[Deep Learning Paper Implementations: Spatial Transformer Networks - Part II](https://kevinzakka.github.io/2017/01/18/stn-part2/)

**Transformer**  
[The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)  
[Transformer Architecture: The Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)

**Variational Inference**  
[A Beginner's Guide to Variational Methods: Mean-Field Approximation](https://blog.evjang.com/2016/08/variational-bayes.html)  
[Variational inference](https://ermongroup.github.io/cs228-notes/inference/variational/)  
[Variational Inference: A Review for Statisticians](https://arxiv.org/pdf/1601.00670.pdf)